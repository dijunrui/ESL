## 1. Introduction

Core concept: To augment and replace the vector of inputs $X$ with additional variables which are transformations of $X$ and then use the linear models in this new space of derived input features. 

$$f(X) = \sum_{m=1}^M \beta_m h_m(X)$$

where $h_m(X): \mathbb{R}^p\rightarrow \mathbb{R}$ is a transformation of $X$. This is called a linear basis expansion in $X$. 

## 2. Peicewise Polynomials and Splines (restricted model)

Dividing the domain of $X$ into contiguous intervals, and representing $f$ by a separate polynomial in each interval. 

An order-$M$ (degree of the polynomial plus 1, i.e. cubic spline has $M=4$) spline with knots $\xi_j$, $j = 1\dots K$ is a piecewise polynomial of order $M$, and has continuous derivatives up to order $M-2$. The form of the truncate power basis is 

$$
\begin{aligned}
h_j(X) &= X^{j-1}, j = 1\dots M\\
h_{M+l}(x) &= (X-\xi_l)_{+}^{M-1}, l = 1...K
\end{aligned}$$

Cubic spline is typically good enough to depict continuity unless we need smooth derivatives. 

One approach is to parametrize a family of spline by the number of basis functions or degree of freedom and have the observations $x_i$ determine the positions of the knots

### 2.1 Natural Cubic Splines

An NCS adds additional constraints, namely that the function is linear bey9ond the boudary knots which frees up four degrees of freedom (two constraints each in both boundary regions)

An NCS with K knots is represented by $K$ basis functions. 

$$N_1(X) = 1, N_2(X) = X, N_{k+2}(X)=d_k(X) - d_{k-1}(X)$$
$$d_k(X) = \frac{(X-\xi_k)^3_+ -(X-\xi_K)^3_+}{\xi_K - \xi_k}$$



## 3. Filtering and Feature Extraction

## 4. Smoothing Spines

Smoothing splines aviods the knot selection porblem compeltely by using a maximal set of knots. The complexity of the fit is controlled by regularization. 

$$RSS(f,\lambda) = \sum_{i=1}^N\{y_i - f(x_i)\}^3 + \lambda\int \{f''(t)\}^2dt$$

The penalty term penalizes curvature in the function using the smoothing parameter $\lambda$. $\lambda = 0$: $f$ is any function that interpolates the data. $\lambda = \infty$: simple least squares linear fit with no second derivative tolerated.  The results has a unique minimizer which is a natural cubic spline with knots at the unique values of the $x_i$. The solution can be written as 

$$f(x) = \sum_{j=1}^NN_j(x)\theta_j$$

where $N_j(x)$ are an $N$-dimensional set of basis functions for representing this family of natural splines. 

The criterion thus reduces to 
$$RSS(\theta,\lambda) = (\by- \mathbf{N}\theta)^T(\by- \mathbf{N}\theta) + \lambda \theta^T\mathbf{\Omega}_N\theta$$
where $\{\mathbf{N}\}_{ij} = N_j(x_i)$ and $\{\mathbf{\Omega}_N\}_{jk} = \int N^{''}_j(t)N^{''}_k(t)dt$, with the solution

$$\hat{\theta} = (\mathbf{N}^T\mathbf{B}+\lambda\mathbf{\Omega}_N)^{-1}\mathbf{N}^T\mathbf{y}$$

## 4.1 Degress of Freedom and Smoother Matrices

Fotted value can be written as

$$\hat{\mathbf{f}} = \mathbf{N}(\mathbf{N}^T\mathbf{B}+\lambda\mathbf{\Omega}_N)^{-1}\mathbf{N}^T\mathbf{y} = \mathbf{S}_\lambda y$$

$\mathbf{S}_\lambda$ is known as the smoot her matrix, which depends only on $x_i$ and $\lambda$.